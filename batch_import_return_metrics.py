#!/usr/bin/env python3
"""
æ‰¹é‡å°å…¥ç¾æœ‰çš„ FR_return_list CSV æ–‡ä»¶åˆ°æ•¸æ“šåº«
è§£æ±ºç”±æ–¼ä¹‹å‰ database_operations bug å°è‡´çš„æ•¸æ“šç¼ºå¤±å•é¡Œ
"""

import os
import pandas as pd
from database_operations import DatabaseManager
from datetime import datetime
import glob

def batch_import_csv_to_database():
    """æ‰¹é‡å°å…¥æ‰€æœ‰ FR_return_list CSV æ–‡ä»¶åˆ°æ•¸æ“šåº«"""
    
    print("\n" + "="*50)
    print("ğŸ“Š æ‰¹é‡å°å…¥ FR_return_list åˆ°æ•¸æ“šåº«")
    print("="*50)
    
    project_root = os.path.dirname(os.path.abspath(__file__))
    fr_return_list_folder = os.path.join(project_root, "csv", "FR_return_list")
    
    if not os.path.exists(fr_return_list_folder):
        print(f"âŒ FR_return_list è³‡æ–™å¤¾ä¸å­˜åœ¨: {fr_return_list_folder}")
        return
    
    # æ‰¾åˆ°æ‰€æœ‰ CSV æ–‡ä»¶
    csv_pattern = os.path.join(fr_return_list_folder, "FR_return_list_*.csv")
    csv_files = glob.glob(csv_pattern)
    csv_files.sort()  # æŒ‰æ—¥æœŸæ’åº
    
    if not csv_files:
        print("âŒ æ²’æœ‰æ‰¾åˆ° FR_return_list CSV æ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} å€‹ CSV æ–‡ä»¶")
    
    # åˆå§‹åŒ–æ•¸æ“šåº«
    db = DatabaseManager()
    
    # çµ±è¨ˆ
    total_files = len(csv_files)
    processed_files = 0
    total_records = 0
    failed_files = []
    
    # æ¬„ä½æ˜ å°„
    column_mapping = {
        'Trading_Pair': 'trading_pair',
        'Date': 'date',
        '1d_return': 'return_1d',
        '1d_ROI': 'roi_1d',
        '2d_return': 'return_2d', 
        '2d_ROI': 'roi_2d',
        '7d_return': 'return_7d',
        '7d_ROI': 'roi_7d',
        '14d_return': 'return_14d',
        '14d_ROI': 'roi_14d',
        '30d_return': 'return_30d',
        '30d_ROI': 'roi_30d',
        'all_return': 'return_all',
        'all_ROI': 'roi_all'
    }
    
    print(f"\nğŸš€ é–‹å§‹æ‰¹é‡å°å…¥...")
    
    for csv_file in csv_files:
        try:
            # å¾æ–‡ä»¶åæå–æ—¥æœŸ
            filename = os.path.basename(csv_file)
            date_str = filename.replace('FR_return_list_', '').replace('.csv', '')
            
            print(f"ğŸ“Š è™•ç† {date_str}...")
            
            # è®€å– CSV
            daily_results = pd.read_csv(csv_file)
            
            if daily_results.empty:
                print(f"âš ï¸  {date_str} CSV æ–‡ä»¶ç‚ºç©ºï¼Œè·³é")
                continue
            
            # æº–å‚™æ•¸æ“šåº«æ•¸æ“š
            db_df = daily_results.copy()
            
            # æ¬„ä½æ˜ å°„
            for old_col, new_col in column_mapping.items():
                if old_col in db_df.columns:
                    db_df[new_col] = db_df[old_col]
            
            # ç¢ºä¿æœ‰æ‰€æœ‰å¿…éœ€çš„æ¬„ä½
            required_columns = ['trading_pair', 'date', 'return_1d', 'roi_1d', 'return_2d', 'roi_2d',
                               'return_7d', 'roi_7d', 'return_14d', 'roi_14d', 'return_30d', 'roi_30d',
                               'return_all', 'roi_all']
            
            for col in required_columns:
                if col not in db_df.columns:
                    db_df[col] = 0.0  # é è¨­å€¼
            
            # é¸æ“‡éœ€è¦çš„æ¬„ä½
            db_df = db_df[required_columns].copy()
            
            # æ’å…¥æ•¸æ“šåº«
            inserted_count = db.insert_return_metrics(db_df)
            
            if inserted_count > 0:
                processed_files += 1
                total_records += inserted_count
                print(f"  âœ… æˆåŠŸæ’å…¥: {inserted_count} æ¢è¨˜éŒ„")
            else:
                print(f"  âš ï¸  æ’å…¥å¤±æ•—: 0 æ¢è¨˜éŒ„")
                failed_files.append((date_str, "æ’å…¥è¿”å› 0"))
            
        except Exception as e:
            print(f"  âŒ è™•ç†å¤±æ•—: {e}")
            failed_files.append((date_str, str(e)))
    
    # ç¸½çµå ±å‘Š
    print(f"\nğŸ‰ æ‰¹é‡å°å…¥å®Œæˆï¼")
    print(f"   ğŸ“Š ç¸½æª”æ¡ˆæ•¸: {total_files}")
    print(f"   âœ… æˆåŠŸè™•ç†: {processed_files}")
    print(f"   ğŸ“ ç¸½è¨˜éŒ„æ•¸: {total_records}")
    
    if failed_files:
        print(f"   âŒ å¤±æ•—æª”æ¡ˆ: {len(failed_files)}")
        for date_str, error in failed_files[:5]:  # é¡¯ç¤ºå‰5å€‹éŒ¯èª¤
            print(f"      - {date_str}: {error}")
        if len(failed_files) > 5:
            print(f"      ... é‚„æœ‰ {len(failed_files) - 5} å€‹å¤±æ•—")
    
    # é©—è­‰çµæœ
    print(f"\nğŸ” æ•¸æ“šåº«é©—è­‰:")
    try:
        result = pd.read_sql_query('SELECT MIN(date) as min_date, MAX(date) as max_date, COUNT(*) as total FROM return_metrics', db.get_connection())
        print(f"   ğŸ“… æ—¥æœŸç¯„åœ: {result.iloc[0]['min_date']} åˆ° {result.iloc[0]['max_date']}")
        print(f"   ğŸ“Š ç¸½è¨˜éŒ„æ•¸: {result.iloc[0]['total']}")
        
        # æª¢æŸ¥å¹¾å€‹é—œéµæ—¥æœŸ
        test_dates = ['2024-01-01', '2024-02-01', '2024-03-01']
        for test_date in test_dates:
            count_result = pd.read_sql_query(f'SELECT COUNT(*) as count FROM return_metrics WHERE date = "{test_date}"', db.get_connection())
            count = count_result.iloc[0]['count']
            print(f"   ğŸ“Š {test_date}: {count} æ¢è¨˜éŒ„")
    
    except Exception as e:
        print(f"   âŒ é©—è­‰å¤±æ•—: {e}")

if __name__ == "__main__":
    batch_import_csv_to_database() 