#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è³‡é‡‘è²»ç‡å·®ç•°è¨ˆç®—æ¨¡çµ„ - Pandaså„ªåŒ–ç‰ˆæœ¬ v3
è§£æ±ºV2ç‰ˆæœ¬çš„INNER JOINå•é¡Œï¼Œå¯¦ç¾å®Œæ•´çš„æ™‚é–“è»¸è¦†è“‹å’Œæ™ºèƒ½å¢é‡è™•ç†

=== V3 ä¸»è¦æ”¹é€² ===
1. ä½¿ç”¨Pandasåœ¨è¨˜æ†¶é«”ä¸­è™•ç†ï¼Œé¿å…SQL JOINä¸Ÿå¤±æ•¸æ“š
2. å‰µå»ºå®Œæ•´æ™‚é–“è»¸ï¼Œç¢ºä¿æ¯å°æ™‚éƒ½æœ‰è¨˜éŒ„
3. å¯¦ç¾æ™ºèƒ½å¢é‡èˆ‡å›å¡«ï¼šè‡ªå‹•æª¢æ¸¬ç¼ºå¤±ç¯„åœä¸¦è£œå……
4. æ­£ç¢ºè™•ç†NULLå€¼ï¼šæœ‰æ•¸æ“š-null=æœ‰æ•¸æ“šï¼Œnull-æœ‰æ•¸æ“š=-æœ‰æ•¸æ“šï¼Œnull-null=null
5. æ”¯æŒéˆæ´»çš„äº¤æ˜“æ‰€çµ„åˆé…ç½®
"""

import os
import pandas as pd
import argparse
import datetime
from pathlib import Path
from typing import List, Tuple, Set, Optional
import numpy as np

# æ·»åŠ æ•¸æ“šåº«æ”¯æŒ
from database_operations import DatabaseManager

# --------------------------------------
# 1. å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„å’Œæ—¥èªŒè¨­å®š
# --------------------------------------
project_root = os.path.dirname(os.path.abspath(__file__))
LOG_FILE = os.path.join(project_root, "logs", "calculate_FR_diff_log.txt")

# ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)

def log_message(msg):
    """è¨˜éŒ„æ—¥èªŒè¨Šæ¯"""
    timestamp = datetime.datetime.now(datetime.timezone.utc).strftime("%Y-%m-%d %H:%M:%S")
    line = f"{timestamp} - {msg}"
    print(line)
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(line + "\n")

# --------------------------------------
# 2. æ™ºèƒ½å¢é‡æª¢æ¸¬èˆ‡ç¯„åœè¨ˆç®—
# --------------------------------------
def get_data_range_info(symbol: str = None) -> dict:
    """
    ç²å–ä¾†æºæ•¸æ“šå’Œçµæœæ•¸æ“šçš„ç¯„åœä¿¡æ¯
    
    Returns:
        dict: åŒ…å«ä¾†æºå’Œçµæœæ•¸æ“šç¯„åœçš„ä¿¡æ¯
    """
    db = DatabaseManager()
    
    try:
        # æŸ¥è©¢ä¾†æºæ•¸æ“šç¯„åœ
        source_query = """
            SELECT 
                MIN(timestamp_utc) as earliest_timestamp,
                MAX(timestamp_utc) as latest_timestamp,
                COUNT(*) as total_records,
                COUNT(DISTINCT symbol) as unique_symbols
            FROM funding_rate_history
        """
        source_params = []
        
        if symbol:
            source_query += " WHERE symbol = ?"
            source_params.append(symbol)
        
        with db.get_connection() as conn:
            source_info = pd.read_sql_query(source_query, conn, params=source_params).iloc[0]
        
        # æŸ¥è©¢çµæœæ•¸æ“šç¯„åœ
        result_query = """
            SELECT 
                MIN(timestamp_utc) as earliest_timestamp,
                MAX(timestamp_utc) as latest_timestamp,
                COUNT(*) as total_records,
                COUNT(DISTINCT symbol) as unique_symbols
            FROM funding_rate_diff
        """
        result_params = []
        
        if symbol:
            result_query += " WHERE symbol = ?"
            result_params.append(symbol)
        
        with db.get_connection() as conn:
            result_info = pd.read_sql_query(result_query, conn, params=result_params).iloc[0]
        
        return {
            'source': {
                'earliest': source_info['earliest_timestamp'],
                'latest': source_info['latest_timestamp'],
                'records': source_info['total_records'],
                'symbols': source_info['unique_symbols']
            },
            'result': {
                'earliest': result_info['earliest_timestamp'],
                'latest': result_info['latest_timestamp'],
                'records': result_info['total_records'],
                'symbols': result_info['unique_symbols']
            }
        }
        
    except Exception as e:
        log_message(f"âš ï¸ ç²å–æ•¸æ“šç¯„åœä¿¡æ¯æ™‚å‡ºéŒ¯: {e}")
        return {
            'source': {'earliest': None, 'latest': None, 'records': 0, 'symbols': 0},
            'result': {'earliest': None, 'latest': None, 'records': 0, 'symbols': 0}
        }

def calculate_processing_ranges(symbol: str = None, start_date: str = None, end_date: str = None) -> List[Tuple[str, str]]:
    """
    æ™ºèƒ½è¨ˆç®—éœ€è¦è™•ç†çš„æ—¥æœŸç¯„åœ
    
    Args:
        symbol: æŒ‡å®šäº¤æ˜“å°ï¼ˆå¯é¸ï¼‰
        start_date: ç”¨æˆ¶æŒ‡å®šé–‹å§‹æ—¥æœŸï¼ˆå¯é¸ï¼‰
        end_date: ç”¨æˆ¶æŒ‡å®šçµæŸæ—¥æœŸï¼ˆå¯é¸ï¼‰
    
    Returns:
        List[Tuple[str, str]]: éœ€è¦è™•ç†çš„æ—¥æœŸç¯„åœåˆ—è¡¨ [(start, end), ...]
    """
    log_message("ğŸ” åˆ†ææ•¸æ“šç¯„åœï¼Œè¨ˆç®—è™•ç†ç­–ç•¥...")
    
    range_info = get_data_range_info(symbol)
    source_info = range_info['source']
    result_info = range_info['result']
    
    log_message(f"ğŸ“Š ä¾†æºæ•¸æ“šç¯„åœ: {source_info['earliest']} ~ {source_info['latest']} ({source_info['records']} æ¢)")
    log_message(f"ğŸ“Š çµæœæ•¸æ“šç¯„åœ: {result_info['earliest']} ~ {result_info['latest']} ({result_info['records']} æ¢)")
    
    # å¦‚æœç”¨æˆ¶æŒ‡å®šäº†æ—¥æœŸç¯„åœï¼Œç›´æ¥ä½¿ç”¨
    if start_date and end_date:
        log_message(f"ğŸ“… ä½¿ç”¨ç”¨æˆ¶æŒ‡å®šç¯„åœ: {start_date} ~ {end_date}")
        return [(start_date, end_date)]
    
    # å¦‚æœä¾†æºæ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•è™•ç†
    if not source_info['earliest'] or source_info['records'] == 0:
        log_message("âš ï¸ ä¾†æºæ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•è¨ˆç®—å·®ç•°")
        return []
    
    # å¦‚æœçµæœæ•¸æ“šç‚ºç©ºï¼Œè™•ç†å…¨éƒ¨ä¾†æºæ•¸æ“š
    if not result_info['earliest'] or result_info['records'] == 0:
        log_message("ğŸ“ çµæœæ•¸æ“šç‚ºç©ºï¼Œå°‡è™•ç†å…¨éƒ¨ä¾†æºæ•¸æ“š")
        source_start = pd.to_datetime(source_info['earliest']).strftime('%Y-%m-%d')
        source_end = pd.to_datetime(source_info['latest']).strftime('%Y-%m-%d')
        return [(source_start, source_end)]
    
    # æ™ºèƒ½å¢é‡èˆ‡å›å¡«ç­–ç•¥
    processing_ranges = []
    
    source_start = pd.to_datetime(source_info['earliest'])
    source_end = pd.to_datetime(source_info['latest'])
    result_start = pd.to_datetime(result_info['earliest'])
    result_end = pd.to_datetime(result_info['latest'])
    
    # 1. å›å¡«æ­·å²ç©ºæ´ï¼ˆä¾†æºæ•¸æ“šæ›´æ—©ï¼‰
    if source_start < result_start:
        backfill_end = (result_start - pd.Timedelta(days=1)).strftime('%Y-%m-%d')
        processing_ranges.append((source_start.strftime('%Y-%m-%d'), backfill_end))
        log_message(f"ğŸ“ˆ æ·»åŠ æ­·å²å›å¡«ç¯„åœ: {source_start.strftime('%Y-%m-%d')} ~ {backfill_end}")
    
    # 2. è¿½åŠ æ–°æ•¸æ“šï¼ˆä¾†æºæ•¸æ“šæ›´æ–°ï¼‰
    if source_end > result_end:
        # è¨ˆç®—éœ€è¦è™•ç†çš„æ–°æ•¸æ“šç¯„åœ
        # æ³¨æ„ï¼šæˆ‘å€‘éœ€è¦åŸºæ–¼å°æ™‚è€Œä¸æ˜¯å¤©ä¾†è¨ˆç®—
        append_start = (result_end + pd.Timedelta(hours=1)).strftime('%Y-%m-%d %H:%M:%S')
        append_end = source_end.strftime('%Y-%m-%d %H:%M:%S')
        
        # è½‰æ›ç‚ºæ—¥æœŸæ ¼å¼ç”¨æ–¼æŸ¥è©¢
        append_start_date = (result_end + pd.Timedelta(hours=1)).strftime('%Y-%m-%d')
        append_end_date = source_end.strftime('%Y-%m-%d')
        
        processing_ranges.append((append_start_date, append_end_date))
        log_message(f"ğŸ“Š æ·»åŠ æ–°æ•¸æ“šç¯„åœ: {append_start} ~ {append_end} (æŸ¥è©¢ç¯„åœ: {append_start_date} ~ {append_end_date})")
    
    # å¦‚æœæ²’æœ‰éœ€è¦è™•ç†çš„ç¯„åœ
    if not processing_ranges:
        log_message("âœ… æ•¸æ“šå·²æ˜¯æœ€æ–°ï¼Œç„¡éœ€è™•ç†")
    
    return processing_ranges

# --------------------------------------
# 3. ç²å–è³‡é‡‘è²»ç‡æ­·å²æ•¸æ“š
# --------------------------------------
def get_fr_history(symbol: str = None, exchanges: List[str] = None, start_date: str = None, end_date: str = None) -> pd.DataFrame:
    """
    å¾æ•¸æ“šåº«ç²å–è³‡é‡‘è²»ç‡æ­·å²æ•¸æ“š
    
    Args:
        symbol: äº¤æ˜“å°ç¬¦è™Ÿ
        exchanges: äº¤æ˜“æ‰€åˆ—è¡¨
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
    
    Returns:
        DataFrame: è³‡é‡‘è²»ç‡æ­·å²æ•¸æ“š
    """
    db = DatabaseManager()
    
    # æ§‹å»ºæŸ¥è©¢
    query = "SELECT * FROM funding_rate_history WHERE 1=1"
    params = []
    
    if symbol:
        query += " AND symbol = ?"
        params.append(symbol)
    
    if exchanges:
        exchange_placeholders = ','.join(['?' for _ in exchanges])
        query += f" AND exchange IN ({exchange_placeholders})"
        params.extend(exchanges)
    
    if start_date:
        query += " AND DATE(timestamp_utc) >= ?"
        params.append(start_date)
    
    if end_date:
        query += " AND DATE(timestamp_utc) <= ?"
        params.append(end_date)
    
    query += " ORDER BY timestamp_utc, symbol, exchange"
    
    log_message(f"ğŸ” æŸ¥è©¢è³‡é‡‘è²»ç‡æ­·å²æ•¸æ“š: {len(params)} å€‹åƒæ•¸")
    
    with db.get_connection() as conn:
        df = pd.read_sql_query(query, conn, params=params)
    
    if not df.empty:
        df['timestamp_utc'] = pd.to_datetime(df['timestamp_utc'])
        log_message(f"âœ… ç²å–åˆ° {len(df)} æ¢æ­·å²æ•¸æ“š")
        log_message(f"   ğŸ“… æ™‚é–“ç¯„åœ: {df['timestamp_utc'].min()} ~ {df['timestamp_utc'].max()}")
        log_message(f"   ğŸ”— äº¤æ˜“å°: {df['symbol'].nunique()}")
        log_message(f"   ğŸ¢ äº¤æ˜“æ‰€: {df['exchange'].nunique()}")
    else:
        log_message("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„æ­·å²æ•¸æ“š")
    
    return df

# --------------------------------------
# 4. Pandasç‰ˆæœ¬å·®ç•°è¨ˆç®—ï¼ˆè§£æ±ºINNER JOINå•é¡Œï¼‰
# --------------------------------------
def calculate_diff_for_symbol(symbol_data: pd.DataFrame, exchange_pairs: List[Tuple[str, str]]) -> pd.DataFrame:
    """
    ç‚ºå–®å€‹äº¤æ˜“å°è¨ˆç®—æ‰€æœ‰äº¤æ˜“æ‰€å°çš„å·®ç•°
    ä½¿ç”¨Pandasé¿å…SQL JOINä¸Ÿå¤±æ•¸æ“šçš„å•é¡Œ
    
    Args:
        symbol_data: å–®å€‹äº¤æ˜“å°çš„è³‡é‡‘è²»ç‡æ•¸æ“š
        exchange_pairs: äº¤æ˜“æ‰€å°åˆ—è¡¨
    
    Returns:
        DataFrame: å·®ç•°è¨ˆç®—çµæœ
    """
    if symbol_data.empty:
        return pd.DataFrame()
    
    symbol = symbol_data['symbol'].iloc[0]
    
    # å‰µå»ºå®Œæ•´æ™‚é–“è»¸
    time_range = pd.date_range(
        start=symbol_data['timestamp_utc'].min(),
        end=symbol_data['timestamp_utc'].max(),
        freq='h'
    )
    
    # é€è¦–è¡¨ï¼šå°‡æ•¸æ“šé‡å¡‘ç‚º timestamp x exchange çš„æ ¼å¼
    pivot_df = symbol_data.pivot_table(
        index='timestamp_utc',
        columns='exchange',
        values='funding_rate',
        aggfunc='first'  # å¦‚æœæœ‰é‡è¤‡ï¼Œå–ç¬¬ä¸€å€‹å€¼
    )
    
    # é‡æ–°ç´¢å¼•åˆ°å®Œæ•´æ™‚é–“è»¸ï¼Œç¼ºå¤±å€¼ä¿æŒç‚ºNaN
    pivot_df = pivot_df.reindex(time_range)
    
    # è¨ˆç®—æ‰€æœ‰äº¤æ˜“æ‰€å°çš„å·®ç•°
    diff_results = []
    
    for exchange_a, exchange_b in exchange_pairs:
        if exchange_a not in pivot_df.columns or exchange_b not in pivot_df.columns:
            log_message(f"âš ï¸ {symbol}: ç¼ºå°‘äº¤æ˜“æ‰€æ•¸æ“š {exchange_a} æˆ– {exchange_b}")
            continue
        
        # ç²å–å…©å€‹äº¤æ˜“æ‰€çš„è²»ç‡æ•¸æ“š
        rate_a = pivot_df[exchange_a]
        rate_b = pivot_df[exchange_b]
        
        # è¨ˆç®—å·®ç•°ï¼šå¯¦ç¾æ­£ç¢ºçš„NULLè™•ç†é‚è¼¯
        # æœ‰æ•¸æ“š - null = æœ‰æ•¸æ“š
        # null - æœ‰æ•¸æ“š = -æœ‰æ•¸æ“š  
        # null - null = null
        
        # ä½¿ç”¨è‡ªå®šç¾©é‚è¼¯è™•ç†NULLå€¼
        diff = pd.Series(index=rate_a.index, dtype=float)
        
        for idx in rate_a.index:
            a_val = rate_a.loc[idx]
            b_val = rate_b.loc[idx]
            
            if pd.notna(a_val) and pd.notna(b_val):
                # æœ‰æ•¸æ“š - æœ‰æ•¸æ“š = æ­£å¸¸è¨ˆç®—
                diff.loc[idx] = a_val - b_val
            elif pd.notna(a_val) and pd.isna(b_val):
                # æœ‰æ•¸æ“š - null = æœ‰æ•¸æ“š
                diff.loc[idx] = a_val
            elif pd.isna(a_val) and pd.notna(b_val):
                # null - æœ‰æ•¸æ“š = -æœ‰æ•¸æ“š
                diff.loc[idx] = -b_val
            else:
                # null - null = null
                diff.loc[idx] = np.nan
        
        # å‰µå»ºçµæœDataFrame
        result_df = pd.DataFrame({
            'timestamp_utc': diff.index,
            'symbol': symbol,
            'exchange_a': exchange_a,
            'exchange_b': exchange_b,
            'funding_rate_a': rate_a.values,
            'funding_rate_b': rate_b.values,
            'diff_ab': diff.values
        })
        
        # é‡è¦ï¼šä¿ç•™æ‰€æœ‰è¨˜éŒ„ï¼ŒåŒ…æ‹¬diff_abç‚ºNaNçš„æƒ…æ³
        # é€™è§£æ±ºäº†V2ç‰ˆæœ¬INNER JOINä¸Ÿå¤±æ•¸æ“šçš„å•é¡Œ
        diff_results.append(result_df)
    
    if diff_results:
        final_result = pd.concat(diff_results, ignore_index=True)
        log_message(f"âœ… {symbol}: è¨ˆç®—å®Œæˆ {len(final_result)} æ¢å·®ç•°è¨˜éŒ„")
        return final_result
    else:
        log_message(f"âš ï¸ {symbol}: æ²’æœ‰å¯è¨ˆç®—çš„äº¤æ˜“æ‰€å°")
        return pd.DataFrame()

def calculate_funding_rate_differences_v3(df: pd.DataFrame, exchange_pairs: List[Tuple[str, str]]) -> pd.DataFrame:
    """
    V3ç‰ˆæœ¬ï¼šä½¿ç”¨Pandasè¨ˆç®—è³‡é‡‘è²»ç‡å·®ç•°
    è§£æ±ºV2ç‰ˆæœ¬çš„INNER JOINå•é¡Œ
    
    Args:
        df: è³‡é‡‘è²»ç‡æ­·å²æ•¸æ“š
        exchange_pairs: äº¤æ˜“æ‰€å°åˆ—è¡¨
    
    Returns:
        DataFrame: æ‰€æœ‰å·®ç•°è¨ˆç®—çµæœ
    """
    if df.empty:
        log_message("âš ï¸ è¼¸å…¥æ•¸æ“šç‚ºç©º")
        return pd.DataFrame()
    
    log_message("ğŸš€ V3ç‰ˆæœ¬ï¼šé–‹å§‹Pandaså·®ç•°è¨ˆç®—...")
    log_message(f"ğŸ“Š è¼¸å…¥æ•¸æ“š: {len(df)} æ¢è¨˜éŒ„")
    log_message(f"ğŸ”— äº¤æ˜“å°æ•¸é‡: {df['symbol'].nunique()}")
    log_message(f"ğŸ¢ äº¤æ˜“æ‰€å°: {exchange_pairs}")
    
    all_results = []
    symbols = df['symbol'].unique()
    
    for i, symbol in enumerate(symbols, 1):
        log_message(f"ğŸ“ˆ è™•ç†äº¤æ˜“å° {i}/{len(symbols)}: {symbol}")
        
        # ç²å–è©²äº¤æ˜“å°çš„æ•¸æ“š
        symbol_data = df[df['symbol'] == symbol].copy()
        
        # è¨ˆç®—è©²äº¤æ˜“å°çš„å·®ç•°
        symbol_result = calculate_diff_for_symbol(symbol_data, exchange_pairs)
        
        if not symbol_result.empty:
            all_results.append(symbol_result)
    
    if all_results:
        final_df = pd.concat(all_results, ignore_index=True)
        
        # çµ±è¨ˆä¿¡æ¯
        total_records = len(final_df)
        non_null_records = final_df['diff_ab'].notna().sum()
        null_records = final_df['diff_ab'].isna().sum()
        
        log_message(f"âœ… V3è¨ˆç®—å®Œæˆ!")
        log_message(f"   ğŸ“Š ç¸½è¨˜éŒ„: {total_records}")
        log_message(f"   âœ… æœ‰æ•ˆå·®ç•°: {non_null_records}")
        log_message(f"   âšª NULLå·®ç•°: {null_records}")
        log_message(f"   ğŸ“… æ™‚é–“ç¯„åœ: {final_df['timestamp_utc'].min()} ~ {final_df['timestamp_utc'].max()}")
        
        return final_df
    else:
        log_message("âŒ æ²’æœ‰è¨ˆç®—å‡ºä»»ä½•å·®ç•°æ•¸æ“š")
        return pd.DataFrame()

# --------------------------------------
# 5. è‡ªå®šç¾©æ•¸æ“šåº«æ’å…¥å‡½æ•¸ï¼ˆæ­£ç¢ºè™•ç†NULLå€¼ï¼‰
# --------------------------------------
def insert_fr_diff_with_nulls(db: DatabaseManager, df: pd.DataFrame) -> int:
    """
    è‡ªå®šç¾©æ’å…¥å‡½æ•¸ï¼Œæ­£ç¢ºè™•ç†NULLå€¼
    é¿å…ä½¿ç”¨ç¾æœ‰çš„insert_funding_rate_diffå‡½æ•¸ï¼Œå› ç‚ºå®ƒæœƒå°‡NaNè½‰æ›ç‚º0.0
    
    Args:
        db: æ•¸æ“šåº«ç®¡ç†å™¨
        df: è¦æ’å…¥çš„DataFrame
    
    Returns:
        int: æ’å…¥çš„è¨˜éŒ„æ•¸
    """
    if df.empty:
        return 0
    
    try:
        with db.get_connection() as conn:
            # æº–å‚™æ’å…¥æ•¸æ“š
            data_to_insert = []
            
            for _, row in df.iterrows():
                # è™•ç†æ¯ä¸€è¡Œï¼Œç¢ºä¿NULLå€¼æ­£ç¢ºè™•ç†
                insert_row = []
                
                # timestamp_utc - å¿…éœ€å­—æ®µ
                insert_row.append(row['timestamp_utc'])
                
                # symbol - å¿…éœ€å­—æ®µ
                insert_row.append(row['symbol'])
                
                # exchange_a - å¿…éœ€å­—æ®µ
                insert_row.append(row['exchange_a'])
                
                # funding_rate_a - å¯èƒ½ç‚ºNULL
                if pd.isna(row['funding_rate_a']) or row['funding_rate_a'] is None:
                    insert_row.append(None)
                else:
                    insert_row.append(str(row['funding_rate_a']))  # è½‰ç‚ºå­—ç¬¦ä¸²ä»¥ç¬¦åˆTEXTé¡å‹
                
                # exchange_b - å¿…éœ€å­—æ®µ
                insert_row.append(row['exchange_b'])
                
                # funding_rate_b - å¯èƒ½ç‚ºNULL
                if pd.isna(row['funding_rate_b']) or row['funding_rate_b'] is None:
                    insert_row.append(None)
                else:
                    insert_row.append(str(row['funding_rate_b']))  # è½‰ç‚ºå­—ç¬¦ä¸²ä»¥ç¬¦åˆTEXTé¡å‹
                
                # diff_ab - å¯èƒ½ç‚ºNULLï¼Œä½†æ•¸æ“šåº«å®šç¾©ç‚ºNOT NULL
                if pd.isna(row['diff_ab']) or row['diff_ab'] is None:
                    # æ ¹æ“šæ•¸æ“šåº«schemaï¼Œdiff_abæ˜¯NOT NULLï¼Œä½†æˆ‘å€‘çš„æ¥­å‹™é‚è¼¯éœ€è¦è™•ç†null-nullçš„æƒ…æ³
                    # ç‚ºäº†ä¿æŒæ¯å°æ™‚éƒ½æœ‰è¨˜éŒ„ï¼Œæˆ‘å€‘å°‡null-nullçš„æƒ…æ³è¨­ç‚º0
                    # ä½†åœ¨funding_rate_aå’Œfunding_rate_bä¸­æ­£ç¢ºè¨˜éŒ„NULLå€¼
                    insert_row.append(0.0)  # null-nullçš„å·®ç•°è¨­ç‚º0
                else:
                    # è§£æ±ºæµ®é»æ•¸ç²¾åº¦å•é¡Œï¼šå››æ¨äº”å…¥åˆ°8ä½å°æ•¸
                    rounded_diff = round(float(row['diff_ab']), 8)
                    insert_row.append(rounded_diff)
                
                data_to_insert.append(tuple(insert_row))
            
            if not data_to_insert:
                log_message("âš ï¸ æ²’æœ‰æœ‰æ•ˆæ•¸æ“šå¯æ’å…¥")
                return 0
            
            # æ‰¹é‡æ’å…¥
            conn.executemany('''
                INSERT OR REPLACE INTO funding_rate_diff 
                (timestamp_utc, symbol, exchange_a, funding_rate_a, exchange_b, funding_rate_b, diff_ab)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', data_to_insert)
            
            conn.commit()
            
            log_message(f"âœ… è‡ªå®šç¾©æ’å…¥å®Œæˆ: {len(data_to_insert)} æ¢è¨˜éŒ„")
            return len(data_to_insert)
            
    except Exception as e:
        log_message(f"âŒ è‡ªå®šç¾©æ’å…¥å¤±æ•—: {e}")
        return 0

# --------------------------------------
# 6. ä¿å­˜å·®ç•°æ•¸æ“šåˆ°æ•¸æ“šåº«
# --------------------------------------
def save_fr_diff(df: pd.DataFrame) -> int:
    """
    ä¿å­˜è³‡é‡‘è²»ç‡å·®ç•°æ•¸æ“šåˆ°æ•¸æ“šåº«
    
    Args:
        df: å·®ç•°æ•¸æ“šDataFrame
    
    Returns:
        int: æˆåŠŸä¿å­˜çš„è¨˜éŒ„æ•¸
    """
    if df.empty:
        log_message("âš ï¸ æ²’æœ‰æ•¸æ“šéœ€è¦ä¿å­˜")
        return 0
    
    try:
        db = DatabaseManager()
        
        # æº–å‚™æ•¸æ“šï¼šè™•ç†æ™‚é–“æˆ³æ ¼å¼å’ŒNULLå€¼
        save_df = df.copy()
        
        # è½‰æ›æ™‚é–“æˆ³ç‚ºå­—ç¬¦ä¸²æ ¼å¼
        save_df['timestamp_utc'] = pd.to_datetime(save_df['timestamp_utc']).dt.strftime('%Y-%m-%d %H:%M:%S')
        
        # æ­£ç¢ºè™•ç†NULLå€¼ï¼šç”±æ–¼æ•¸æ“šåº«schemaä¸­funding_rate_a/bæ˜¯TEXTé¡å‹
        # æˆ‘å€‘éœ€è¦å°‡NaNè½‰æ›ç‚ºNoneï¼Œä¸¦ç¢ºä¿æ•¸å€¼é¡å‹æ­£ç¢º
        
        # å°æ–¼æ•¸å€¼åˆ—ï¼Œå°‡NaNè½‰æ›ç‚ºNone
        numeric_columns = ['funding_rate_a', 'funding_rate_b', 'diff_ab']
        for col in numeric_columns:
            if col in save_df.columns:
                # å°‡NaNè½‰æ›ç‚ºNoneï¼Œä¿æŒå…¶ä»–å€¼ä¸è®Š
                save_df[col] = save_df[col].where(pd.notna(save_df[col]), None)
        
        # å°æ–¼å­—ç¬¦ä¸²åˆ—ï¼Œç¢ºä¿Noneå€¼æ­£ç¢ºè™•ç†
        string_columns = ['symbol', 'exchange_a', 'exchange_b']
        for col in string_columns:
            if col in save_df.columns:
                save_df[col] = save_df[col].where(pd.notna(save_df[col]), None)
        
        log_message(f"ğŸ’¾ é–‹å§‹ä¿å­˜ {len(save_df)} æ¢å·®ç•°æ•¸æ“š...")
        
        # èª¿è©¦ä¿¡æ¯ï¼šæª¢æŸ¥NULLå€¼è™•ç†
        null_counts = {}
        for col in ['funding_rate_a', 'funding_rate_b', 'diff_ab']:
            if col in save_df.columns:
                null_count = save_df[col].isna().sum()
                null_counts[col] = null_count
        
        log_message(f"ğŸ“Š NULLå€¼çµ±è¨ˆ: {null_counts}")
        
        # è‡ªå®šç¾©æ’å…¥æ–¹æ³•ï¼šæ­£ç¢ºè™•ç†NULLå€¼
        inserted_count = insert_fr_diff_with_nulls(db, save_df)
        
        log_message(f"âœ… æˆåŠŸä¿å­˜ {inserted_count} æ¢å·®ç•°æ•¸æ“š")
        return inserted_count
        
    except Exception as e:
        log_message(f"âŒ ä¿å­˜å·®ç•°æ•¸æ“šæ™‚å‡ºéŒ¯: {e}")
        return 0

# --------------------------------------
# 7. ä¸»ç¨‹å¼
# --------------------------------------
def main():
    log_message("ğŸš€ è³‡é‡‘è²»ç‡å·®ç•°è¨ˆç®—ç¨‹å¼å•Ÿå‹• (V3ç‰ˆæœ¬)")
    
    parser = argparse.ArgumentParser(description="è¨ˆç®—äº¤æ˜“æ‰€é–“è³‡é‡‘è²»ç‡å·®ç•° - V3ç‰ˆæœ¬ (Pandaså„ªåŒ–)")
    parser.add_argument("--symbol", help="æŒ‡å®šäº¤æ˜“å°ç¬¦è™Ÿ (å¯é¸)")
    parser.add_argument("--start-date", help="é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--end-date", help="çµæŸæ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--exchanges", nargs='+', default=['binance', 'bybit'],
                        help="è¦æ¯”è¼ƒçš„äº¤æ˜“æ‰€åˆ—è¡¨")
    parser.add_argument("--force-full", action='store_true', 
                        help="å¼·åˆ¶å…¨é‡è¨ˆç®—ï¼Œå¿½ç•¥å¢é‡æª¢æ¸¬")
    
    args = parser.parse_args()
    
    log_message("=" * 60)
    log_message("ğŸ“… è³‡é‡‘è²»ç‡å·®ç•°è¨ˆç®— V3 (Pandaså„ªåŒ–ç‰ˆæœ¬)")
    log_message("=" * 60)
    log_message(f"åƒæ•¸: symbol={args.symbol}")
    log_message(f"æ—¥æœŸ: {args.start_date} ~ {args.end_date}")
    log_message(f"äº¤æ˜“æ‰€: {args.exchanges}")
    log_message(f"å¼·åˆ¶å…¨é‡: {args.force_full}")
    
    try:
        # ç”Ÿæˆäº¤æ˜“æ‰€å°çµ„åˆ
        exchange_pairs = []
        exchanges = args.exchanges
        for i in range(len(exchanges)):
            for j in range(i + 1, len(exchanges)):
                exchange_pairs.append((exchanges[i], exchanges[j]))
        
        log_message(f"å°‡è¨ˆç®—ä»¥ä¸‹äº¤æ˜“æ‰€å°çš„å·®ç•°: {exchange_pairs}")
        
        # ç¢ºå®šè™•ç†ç¯„åœ
        if args.force_full or (args.start_date and args.end_date):
            # ä½¿ç”¨æŒ‡å®šç¯„åœæˆ–å¼·åˆ¶å…¨é‡
            if args.start_date and args.end_date:
                processing_ranges = [(args.start_date, args.end_date)]
            else:
                # å¼·åˆ¶å…¨é‡ï¼šæŸ¥è©¢æ‰€æœ‰ä¾†æºæ•¸æ“šç¯„åœ
                range_info = get_data_range_info(args.symbol)
                if range_info['source']['earliest']:
                    start = pd.to_datetime(range_info['source']['earliest']).strftime('%Y-%m-%d')
                    end = pd.to_datetime(range_info['source']['latest']).strftime('%Y-%m-%d')
                    processing_ranges = [(start, end)]
                else:
                    log_message("âŒ æ²’æœ‰ä¾†æºæ•¸æ“šå¯è™•ç†")
                    return
        else:
            # æ™ºèƒ½å¢é‡è™•ç†
            processing_ranges = calculate_processing_ranges(args.symbol)
        
        if not processing_ranges:
            log_message("âœ… æ²’æœ‰éœ€è¦è™•ç†çš„æ•¸æ“šç¯„åœ")
            return
        
        total_processed = 0
        
        # è™•ç†æ¯å€‹ç¯„åœ
        for start_date, end_date in processing_ranges:
            log_message(f"ğŸ”„ è™•ç†ç¯„åœ: {start_date} ~ {end_date}")
            
            # ç²å–è³‡é‡‘è²»ç‡æ­·å²æ•¸æ“š
            df = get_fr_history(
                symbol=args.symbol,
                exchanges=args.exchanges,
                start_date=start_date,
                end_date=end_date
            )
            
            if df.empty:
                log_message(f"âš ï¸ ç¯„åœ {start_date} ~ {end_date} æ²’æœ‰æ•¸æ“š")
                continue
            
            # è¨ˆç®—å·®ç•°
            diff_df = calculate_funding_rate_differences_v3(df, exchange_pairs)
            
            if diff_df.empty:
                log_message(f"âš ï¸ ç¯„åœ {start_date} ~ {end_date} æ²’æœ‰è¨ˆç®—å‡ºå·®ç•°")
                continue
            
            # ä¿å­˜åˆ°æ•¸æ“šåº«
            saved_count = save_fr_diff(diff_df)
            total_processed += saved_count
            
            log_message(f"âœ… ç¯„åœ {start_date} ~ {end_date} è™•ç†å®Œæˆ: {saved_count} æ¢")
        
        log_message("=" * 60)
        log_message(f"ğŸ‰ V3ç‰ˆæœ¬è™•ç†å®Œæˆï¼ç¸½å…±è™•ç† {total_processed} æ¢è¨˜éŒ„")
        log_message("=" * 60)
        
    except Exception as e:
        log_message(f"âŒ ç¨‹å¼åŸ·è¡Œå‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 