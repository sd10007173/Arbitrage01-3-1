#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è³‡é‡‘è²»ç‡æ”¶ç›Šè¨ˆç®—æ¨¡çµ„
å¾æ•¸æ“šåº«è®€å–funding_rate_diffæ•¸æ“šï¼Œè¨ˆç®—å„ç¨®æ™‚é–“é€±æœŸçš„æ”¶ç›ŠæŒ‡æ¨™
è¼¸å‡ºåˆ°æ•¸æ“šåº«: return_metricsè¡¨
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import argparse

# æ·»åŠ æ•¸æ“šåº«æ”¯æŒ
from database_operations import DatabaseManager

def load_fr_diff_data_from_database(start_date=None, end_date=None, symbol=None):
    """
    å¾æ•¸æ“šåº«åŠ è¼‰æŒ‡å®šæ™‚é–“ç¯„åœå…§çš„æ‰€æœ‰FR_diffæ•¸æ“š
    Args:
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
        symbol: äº¤æ˜“å°ç¬¦è™Ÿ (å¯é¸)
    Returns:
        DataFrame with FRå·®ç•°æ•¸æ“š
    """
    try:
        db = DatabaseManager()
        
        print(f"ğŸ“Š æ­£åœ¨å¾æ•¸æ“šåº«åŠ è¼‰FR_diffæ•¸æ“š...")
        if start_date and end_date:
            print(f"   æ™‚é–“ç¯„åœ: {start_date} åˆ° {end_date}")
        if symbol:
            print(f"   äº¤æ˜“å°: {symbol}")
        
        # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
        where_conditions = []
        params = []
        
        if start_date:
            where_conditions.append("DATE(timestamp_utc) >= ?")
            params.append(start_date)
            
        if end_date:
            where_conditions.append("DATE(timestamp_utc) <= ?") 
            params.append(end_date)
            
        if symbol:
            where_conditions.append("symbol = ?")
            params.append(symbol)
        
        where_clause = "WHERE " + " AND ".join(where_conditions) if where_conditions else ""
        
        query = f"""
            SELECT timestamp_utc, symbol, exchange_a, exchange_b, diff_ab,
                   symbol || '_' || exchange_a || '_' || exchange_b as trading_pair
            FROM funding_rate_diff 
            {where_clause}
            ORDER BY timestamp_utc, symbol, exchange_a, exchange_b
        """
        
        with db.get_connection() as conn:
            df = pd.read_sql_query(query, conn, params=params)
        
        if df.empty:
            print("âš ï¸ æ•¸æ“šåº«ä¸­æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„FR_diffæ•¸æ“š")
            return pd.DataFrame()
        
        # è½‰æ›æ™‚é–“æˆ³ä¸¦é‡å‘½ååˆ—ä»¥ä¿æŒå…¼å®¹æ€§
        df['timestamp_utc'] = pd.to_datetime(df['timestamp_utc'])
        df = df.rename(columns={
            'timestamp_utc': 'Timestamp (UTC)',
            'trading_pair': 'Trading_Pair',
            'diff_ab': 'Diff_AB'
        })
        
        print(f"âœ… æˆåŠŸåŠ è¼‰ {len(df)} è¡ŒFR_diffæ•¸æ“š")
        print(f"   äº¤æ˜“å°æ•¸é‡: {df['Trading_Pair'].nunique()}")
        print(f"   æ™‚é–“ç¯„åœ: {df['Timestamp (UTC)'].min()} åˆ° {df['Timestamp (UTC)'].max()}")
        
        return df
        
    except Exception as e:
        print(f"âŒ å¾æ•¸æ“šåº«åŠ è¼‰FR_diffæ•¸æ“šæ™‚å‡ºéŒ¯: {e}")
        return pd.DataFrame()

def calculate_returns(df, trading_pair, target_date):
    """
    è¨ˆç®—æŒ‡å®šäº¤æ˜“å°åœ¨ç›®æ¨™æ—¥æœŸçš„å„ç¨®æ”¶ç›ŠæŒ‡æ¨™
    Args:
        df: FRå·®ç•°æ•¸æ“šDataFrame
        trading_pair: äº¤æ˜“å°åç¨± (å¦‚ BTCUSDT_binance_bybit)
        target_date: ç›®æ¨™æ—¥æœŸ (YYYY-MM-DD)
    Returns:
        å­—å…¸åŒ…å«å„æ™‚é–“é€±æœŸçš„æ”¶ç›ŠæŒ‡æ¨™
    """
    target_dt = pd.to_datetime(target_date)
    
    # ç²å–ç›®æ¨™æ—¥æœŸåŠä¹‹å‰çš„æ‰€æœ‰æ•¸æ“š
    historical_data = df[df['Timestamp (UTC)'] <= target_dt + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)].copy()
    
    if historical_data.empty:
        return None
    
    historical_data = historical_data.sort_values('Timestamp (UTC)')
    
    if 'Diff_AB' not in historical_data.columns:
        print(f"è­¦å‘Š: {trading_pair} æ²’æœ‰ Diff_AB åˆ—")
        return None
    
    # æ·»åŠ æ—¥æœŸåˆ—ä»¥ä¾¿æŒ‰æ—¥æœŸåˆ†çµ„
    historical_data['Date'] = historical_data['Timestamp (UTC)'].dt.date
    
    # æŒ‰æ—¥æœŸè¨ˆç®—æ¯æ—¥æ”¶ç›Šï¼šæ¯æ—¥Diff_ABçš„ç¸½å’Œ
    daily_returns = historical_data.groupby('Date')['Diff_AB'].sum().reset_index()
    daily_returns = daily_returns.sort_values('Date')
    
    result = {'Trading_Pair': trading_pair, 'Date': target_date}
    
    # ç²å–ç›®æ¨™æ—¥æœŸåœ¨daily_returnsä¸­çš„ä½ç½®
    target_date_obj = pd.to_datetime(target_date).date()
    
    if target_date_obj not in daily_returns['Date'].values:
        # å¦‚æœç›®æ¨™æ—¥æœŸæ²’æœ‰æ•¸æ“šï¼Œè¿”å›0
        for period_name in ['1d', '2d', '7d', '14d', '30d', 'all']:
            result[f'{period_name}_return'] = 0.0
            result[f'{period_name}_ROI'] = 0.0
        return result
    
    # æ‰¾åˆ°ç›®æ¨™æ—¥æœŸçš„ç´¢å¼•
    target_idx = daily_returns[daily_returns['Date'] == target_date_obj].index[0]
    
    # è¨ˆç®—å„ç¨®æ™‚é–“é€±æœŸçš„æ”¶ç›Š
    periods = {
        '1d': 1,
        '2d': 2, 
        '7d': 7,
        '14d': 14,
        '30d': 30,
        'all': len(daily_returns)
    }
    
    for period_name, days in periods.items():
        # ç²å–å¾ç›®æ¨™æ—¥æœŸå¾€å‰æ¨dayså¤©çš„æ•¸æ“š
        start_idx = max(0, target_idx - days + 1)
        end_idx = target_idx + 1
        
        period_data = daily_returns.iloc[start_idx:end_idx]
        
        if not period_data.empty:
            cumulative_return = period_data['Diff_AB'].sum()
            actual_days = len(period_data)
            
            # å¹´åŒ–æ”¶ç›Šç‡è¨ˆç®—
            if actual_days > 0:
                annualized_roi = (cumulative_return / actual_days) * 365
            else:
                annualized_roi = 0.0
                
            result[f'{period_name}_return'] = cumulative_return
            result[f'{period_name}_ROI'] = annualized_roi
        else:
            result[f'{period_name}_return'] = 0.0
            result[f'{period_name}_ROI'] = 0.0
    
    return result

def process_daily_data(combined_df, target_date):
    """
    è™•ç†æŒ‡å®šæ—¥æœŸçš„æ•¸æ“šï¼Œè¨ˆç®—æ‰€æœ‰äº¤æ˜“å°çš„æ”¶ç›ŠæŒ‡æ¨™
    Args:
        combined_df: åˆä½µçš„FRå·®ç•°æ•¸æ“š
        target_date: ç›®æ¨™æ—¥æœŸ (YYYY-MM-DD)
    Returns:
        DataFrameåŒ…å«æ‰€æœ‰äº¤æ˜“å°çš„æ”¶ç›ŠæŒ‡æ¨™
    """
    print(f"ğŸ“Š æ­£åœ¨è™•ç† {target_date} çš„æ•¸æ“š...")
    
    trading_pairs = combined_df['Trading_Pair'].unique()
    print(f"   æ‰¾åˆ° {len(trading_pairs)} å€‹äº¤æ˜“å°")
    
    results = []
    
    for trading_pair in trading_pairs:
        pair_data = combined_df[combined_df['Trading_Pair'] == trading_pair].copy()
        result = calculate_returns(pair_data, trading_pair, target_date)
        
        if result:
            results.append(result)
    
    if results:
        results_df = pd.DataFrame(results)
        print(f"âœ… æˆåŠŸè¨ˆç®— {len(results_df)} å€‹äº¤æ˜“å°çš„æ”¶ç›ŠæŒ‡æ¨™")
        return results_df
    else:
        print("âš ï¸ æ²’æœ‰è¨ˆç®—å‡ºä»»ä½•æ”¶ç›ŠæŒ‡æ¨™")
        return pd.DataFrame()

def save_returns_to_database(results_df):
    """
    å°‡æ”¶ç›ŠæŒ‡æ¨™ä¿å­˜åˆ°æ•¸æ“šåº«
    Args:
        results_df: åŒ…å«æ”¶ç›ŠæŒ‡æ¨™çš„DataFrame
    Returns:
        ä¿å­˜çš„è¨˜éŒ„æ•¸
    """
    if results_df.empty:
        print("âš ï¸ æ”¶ç›Šæ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•ä¿å­˜")
        return 0
    
    try:
        db = DatabaseManager()
        
        print(f"ğŸ“Š æº–å‚™å°‡ {len(results_df)} æ¢æ”¶ç›ŠæŒ‡æ¨™è¨˜éŒ„æ’å…¥æ•¸æ“šåº«...")
        
        # æº–å‚™æ•¸æ“šåº«æ•¸æ“š
        db_df = results_df.copy()
        
        # è™•ç†åˆ—åæ˜ å°„
        column_mapping = {
            'Trading_Pair': 'trading_pair',
            'Date': 'date',
            '1d_return': 'return_1d',
            '1d_ROI': 'roi_1d',
            '2d_return': 'return_2d', 
            '2d_ROI': 'roi_2d',
            '7d_return': 'return_7d',
            '7d_ROI': 'roi_7d',
            '14d_return': 'return_14d',
            '14d_ROI': 'roi_14d',
            '30d_return': 'return_30d',
            '30d_ROI': 'roi_30d',
            'all_return': 'return_all',
            'all_ROI': 'roi_all'
        }
        
        # é‡å‘½ååˆ—
        for old_col, new_col in column_mapping.items():
            if old_col in db_df.columns:
                db_df[new_col] = db_df[old_col]
        
        # ç¢ºä¿æœ‰æ‰€æœ‰å¿…éœ€çš„åˆ—
        required_columns = ['trading_pair', 'date', 'return_1d', 'roi_1d', 'return_2d', 'roi_2d',
                          'return_7d', 'roi_7d', 'return_14d', 'roi_14d', 'return_30d', 'roi_30d',
                          'return_all', 'roi_all']
        
        for col in required_columns:
            if col not in db_df.columns:
                db_df[col] = 0.0  # é è¨­å€¼
        
        # é¸æ“‡éœ€è¦çš„åˆ—
        db_df = db_df[required_columns].copy()
        
        print(f"ğŸ“Š æ•¸æ“šæ¨£æœ¬: Trading_Pair={db_df.iloc[0]['trading_pair']}, Date={db_df.iloc[0]['date']}")
        
        # ä¿å­˜åˆ°æ•¸æ“šåº«
        inserted_count = db.insert_return_metrics(db_df)
        print(f"âœ… æ•¸æ“šåº«æ’å…¥æˆåŠŸ: {inserted_count} æ¢è¨˜éŒ„")
        
        return inserted_count
        
    except Exception as e:
        print(f"âŒ ä¿å­˜æ”¶ç›Šæ•¸æ“šåˆ°æ•¸æ“šåº«æ™‚å‡ºéŒ¯: {e}")
        return 0

def check_existing_return_data():
    """
    æª¢æŸ¥æ•¸æ“šåº«ä¸­å·²å­˜åœ¨çš„æ”¶ç›Šæ•¸æ“šï¼Œå›å‚³å·²è™•ç†çš„æ—¥æœŸé›†åˆ
    Returns:
        set: å·²è™•ç†çš„æ—¥æœŸé›†åˆ
    """
    print("ğŸ” æª¢æŸ¥æ•¸æ“šåº«ä¸­å·²å­˜åœ¨çš„æ”¶ç›Šæ•¸æ“š...")
    
    try:
        db = DatabaseManager()
        
        # æŸ¥è©¢æ•¸æ“šåº«ä¸­æ‰€æœ‰ä¸é‡è¤‡çš„æ—¥æœŸ
        query = "SELECT DISTINCT date FROM return_metrics ORDER BY date"
        
        with db.get_connection() as conn:
            result = pd.read_sql_query(query, conn)
        
        if result.empty:
            print("ğŸ“Š æ•¸æ“šåº«ä¸­æ²’æœ‰æ”¶ç›Šæ•¸æ“š")
            return set()
        
        existing_dates = set(result['date'].tolist())
        
        print(f"ğŸ“Š æ•¸æ“šåº«ä¸­æ‰¾åˆ° {len(existing_dates)} å€‹å·²è™•ç†çš„æ—¥æœŸ")
        if existing_dates:
            sorted_dates = sorted(existing_dates)
            print(f"ğŸ“… æ•¸æ“šåº«å·²è™•ç†ç¯„åœ: {sorted_dates[0]} åˆ° {sorted_dates[-1]}")
        
        return existing_dates
        
    except Exception as e:
        print(f"âš ï¸ æª¢æŸ¥æ•¸æ“šåº«æ™‚å‡ºéŒ¯: {e}")
        return set()

def auto_detect_date_range():
    """
    è‡ªå‹•æª¢æ¸¬æ•¸æ“šåº«ä¸­funding_rate_diffæ•¸æ“šçš„æ—¥æœŸç¯„åœ
    Returns:
        tuple: (start_date, end_date) æˆ– (None, None)
    """
    print("ğŸ” è‡ªå‹•æƒææ•¸æ“šåº«ä¸­çš„FR_diffæ•¸æ“šç¯„åœ...")
    
    try:
        db = DatabaseManager()
        
        # æŸ¥è©¢æœ€å°å’Œæœ€å¤§æ—¥æœŸ
        query = """
            SELECT MIN(DATE(timestamp_utc)) as min_date, 
                   MAX(DATE(timestamp_utc)) as max_date,
                   COUNT(*) as total_count,
                   COUNT(DISTINCT symbol) as symbol_count
            FROM funding_rate_diff
        """
        
        with db.get_connection() as conn:
            result = conn.execute(query).fetchone()
        
        if not result or result[2] == 0:
            print("âŒ æ•¸æ“šåº«ä¸­æ²’æœ‰æ‰¾åˆ°funding_rate_diffæ•¸æ“š")
            return None, None
        
        min_date = result[0]
        max_date = result[1]
        total_count = result[2]
        symbol_count = result[3]
        
        print(f"ğŸ“ˆ æª¢æ¸¬åˆ°æ•¸æ“šç¯„åœ: {min_date} åˆ° {max_date}")
        print(f"ğŸ“Š ç¸½è¨˜éŒ„æ•¸: {total_count}")
        print(f"ğŸ“… äº¤æ˜“å°æ•¸é‡: {symbol_count}")
        
        return min_date, max_date
        
    except Exception as e:
        print(f"âŒ è‡ªå‹•æª¢æ¸¬æ•¸æ“šç¯„åœæ™‚å‡ºéŒ¯: {e}")
        return None, None

def generate_date_range(start_date, end_date):
    """
    ç”Ÿæˆæ—¥æœŸç¯„åœ
    Args:
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
    Returns:
        list: æ—¥æœŸå­—ç¬¦ä¸²åˆ—è¡¨
    """
    start_dt = datetime.strptime(start_date, '%Y-%m-%d')
    end_dt = datetime.strptime(end_date, '%Y-%m-%d')
    
    dates = []
    current_dt = start_dt
    
    while current_dt <= end_dt:
        dates.append(current_dt.strftime('%Y-%m-%d'))
        current_dt += timedelta(days=1)
    
    return dates

def main():
    parser = argparse.ArgumentParser(description="è¨ˆç®—è³‡é‡‘è²»ç‡æ”¶ç›ŠæŒ‡æ¨™ä¸¦ä¿å­˜åˆ°æ•¸æ“šåº«")
    parser.add_argument("--start_date", help="é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--end_date", help="çµæŸæ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--symbol", help="æŒ‡å®šäº¤æ˜“å°ç¬¦è™Ÿ (å¯é¸)")
    
    args = parser.parse_args()
    
    print("\n" + "="*60)
    print("ğŸ“… è³‡é‡‘è²»ç‡æ”¶ç›Šè¨ˆç®— (æ•¸æ“šåº«ç‰ˆ)")
    print("="*60)
    
    # æª¢æŸ¥å·²å­˜åœ¨çš„æ”¶ç›Šæ•¸æ“š
    existing_dates = check_existing_return_data()
    
    # è‡ªå‹•æª¢æ¸¬æˆ–ä½¿ç”¨æŒ‡å®šçš„æ—¥æœŸç¯„åœ
    if args.start_date and args.end_date:
        start_time = args.start_date
        end_time = args.end_date
        print(f"ğŸ“… ä½¿ç”¨æŒ‡å®šæ—¥æœŸç¯„åœ: {start_time} åˆ° {end_time}")
    else:
        start_time, end_time = auto_detect_date_range()
        
        if start_time is None or end_time is None:
            print("âŒ ç„¡æ³•æª¢æ¸¬æ•¸æ“šç¯„åœ")
            print("ğŸ’¡ æç¤º:")
            print("   1. æª¢æŸ¥æ•¸æ“šåº«ä¸­æ˜¯å¦æœ‰funding_rate_diffæ•¸æ“š")
            print("   2. æˆ–ä½¿ç”¨ --start_date å’Œ --end_date åƒæ•¸æŒ‡å®šç¯„åœ")
            return
    
    # ç”Ÿæˆå®Œæ•´çš„æ—¥æœŸç¯„åœ
    all_dates = generate_date_range(start_time, end_time)
    
    # éæ¿¾å‡ºéœ€è¦è™•ç†çš„æ–°æ—¥æœŸï¼ˆæ’é™¤å·²å­˜åœ¨çš„ï¼‰
    new_dates = [date for date in all_dates if date not in existing_dates]
    
    print(f"\nğŸ“Š æ•¸æ“šåˆ†æçµæœ:")
    print(f"   ğŸ“… å®Œæ•´æ—¥æœŸç¯„åœ: {start_time} åˆ° {end_time} ({len(all_dates)} å¤©)")
    print(f"   âœ… å·²è™•ç†æ—¥æœŸ: {len(existing_dates)} å¤©")
    print(f"   ğŸ†• å¾…è™•ç†æ—¥æœŸ: {len(new_dates)} å¤©")
    
    if not new_dates:
        print("\nğŸ‰ æ‰€æœ‰æ—¥æœŸéƒ½å·²è™•ç†å®Œæˆï¼Œç„¡éœ€é¡å¤–è¨ˆç®—ï¼")
        return
    
    print(f"\nğŸš€ é–‹å§‹è™•ç†...")
    if len(new_dates) <= 10:
        print(f"   æ–°æ—¥æœŸ: {', '.join(new_dates)}")
    else:
        print(f"   æ–°æ—¥æœŸç¯„åœ: {new_dates[0]} åˆ° {new_dates[-1]}")
    
    # å¾æ•¸æ“šåº«è¼‰å…¥FR_diffè³‡æ–™ï¼ˆåªè¼‰å…¥éœ€è¦çš„ç¯„åœï¼‰
    new_start_time = min(new_dates)
    new_end_time = max(new_dates)
    combined_df = load_fr_diff_data_from_database(new_start_time, new_end_time, args.symbol)
    
    if combined_df.empty:
        print("âŒ æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„FR_diffæ•¸æ“š")
        return
    
    processed_count = 0
    total_saved = 0
    
    for date in new_dates:
        print(f"\nğŸ“Š è™•ç†æ—¥æœŸ: {date}")
        
        daily_results = process_daily_data(combined_df, date)
        
        if not daily_results.empty:
            # ä¿å­˜åˆ°æ•¸æ“šåº«
            saved_count = save_returns_to_database(daily_results)
            
            if saved_count > 0:
                total_saved += saved_count
                processed_count += 1
                print(f"âœ… æˆåŠŸè™•ç†æ—¥æœŸ {date}: {saved_count} æ¢è¨˜éŒ„")
            else:
                print(f"âŒ ä¿å­˜æ—¥æœŸ {date} å¤±æ•—")
        else:
            print(f"âš ï¸ æ—¥æœŸ {date} æ²’æœ‰æœ‰æ•ˆæ•¸æ“š")
    
    print(f"\nğŸ‰ è™•ç†å®Œæˆï¼")
    print(f"   ğŸ“Š ç¸½å¾…è™•ç†: {len(new_dates)} å€‹æ—¥æœŸ")
    print(f"   âœ… æˆåŠŸè™•ç†: {processed_count} å€‹æ—¥æœŸ")
    print(f"   ğŸ’¾ ç¸½ä¿å­˜è¨˜éŒ„: {total_saved} æ¢")

if __name__ == "__main__":
    main() 