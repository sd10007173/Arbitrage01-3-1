#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è³‡é‡‘è²»ç‡æ”¶ç›Šè¨ˆç®—æ¨¡çµ„ - åŠ é€Ÿç‰ˆæœ¬ v2
å¾æ•¸æ“šåº«è®€å–funding_rate_diffæ•¸æ“šï¼Œè¨ˆç®—å„ç¨®æ™‚é–“é€±æœŸçš„æ”¶ç›ŠæŒ‡æ¨™
è¼¸å‡ºåˆ°æ•¸æ“šåº«: return_metricsè¡¨

=== æ€§èƒ½å„ªåŒ–ç›®æ¨™ ===
1. æ¸›å°‘é‡è¤‡æ•¸æ“šè¼‰å…¥
2. ä½¿ç”¨SQLé€²è¡Œä¸»è¦è¨ˆç®— 
3. æ‰¹é‡è™•ç†å„ªåŒ–
4. å‘é‡åŒ–æ“ä½œ
5. è¨˜æ†¶é«”ä½¿ç”¨å„ªåŒ–
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import argparse

# æ·»åŠ æ•¸æ“šåº«æ”¯æŒ
from database_operations import DatabaseManager

def load_fr_diff_data_from_database(start_date=None, end_date=None, symbol=None):
    """
    å¾æ•¸æ“šåº«åŠ è¼‰æŒ‡å®šæ™‚é–“ç¯„åœå…§çš„æ‰€æœ‰FR_diffæ•¸æ“š
    Args:
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
        symbol: äº¤æ˜“å°ç¬¦è™Ÿ (å¯é¸)
    Returns:
        DataFrame with FRå·®ç•°æ•¸æ“š
    """
    try:
        db = DatabaseManager()
        
        print(f"ğŸ“Š æ­£åœ¨å¾æ•¸æ“šåº«åŠ è¼‰FR_diffæ•¸æ“š...")
        if start_date and end_date:
            print(f"   æ™‚é–“ç¯„åœ: {start_date} åˆ° {end_date}")
        if symbol:
            print(f"   äº¤æ˜“å°: {symbol}")
        
        # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
        where_conditions = []
        params = []
        
        if start_date:
            where_conditions.append("DATE(timestamp_utc) >= ?")
            params.append(start_date)
            
        if end_date:
            where_conditions.append("DATE(timestamp_utc) <= ?") 
            params.append(end_date)
            
        if symbol:
            where_conditions.append("symbol = ?")
            params.append(symbol)
        
        where_clause = "WHERE " + " AND ".join(where_conditions) if where_conditions else ""
        
        query = f"""
            SELECT timestamp_utc, symbol, exchange_a, exchange_b, diff_ab,
                   symbol || '_' || exchange_a || '_' || exchange_b as trading_pair
            FROM funding_rate_diff 
            {where_clause}
            ORDER BY timestamp_utc, symbol, exchange_a, exchange_b
        """
        
        with db.get_connection() as conn:
            df = pd.read_sql_query(query, conn, params=params)
        
        if df.empty:
            print("âš ï¸ æ•¸æ“šåº«ä¸­æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„FR_diffæ•¸æ“š")
            return pd.DataFrame()
        
        # è½‰æ›æ™‚é–“æˆ³ä¸¦é‡å‘½ååˆ—ä»¥ä¿æŒå…¼å®¹æ€§
        df['timestamp_utc'] = pd.to_datetime(df['timestamp_utc'])
        df = df.rename(columns={
            'timestamp_utc': 'Timestamp (UTC)',
            'trading_pair': 'Trading_Pair',
            'diff_ab': 'Diff_AB'
        })
        
        print(f"âœ… æˆåŠŸåŠ è¼‰ {len(df)} è¡ŒFR_diffæ•¸æ“š")
        print(f"   äº¤æ˜“å°æ•¸é‡: {df['Trading_Pair'].nunique()}")
        print(f"   æ™‚é–“ç¯„åœ: {df['Timestamp (UTC)'].min()} åˆ° {df['Timestamp (UTC)'].max()}")
        
        return df
        
    except Exception as e:
        print(f"âŒ å¾æ•¸æ“šåº«åŠ è¼‰FR_diffæ•¸æ“šæ™‚å‡ºéŒ¯: {e}")
        return pd.DataFrame()

def calculate_returns_sql_optimized(start_date, end_date, symbol=None):
    """
    SQLå„ªåŒ–ç‰ˆæœ¬ï¼šä¸€æ¬¡æ€§è¨ˆç®—æ‰€æœ‰äº¤æ˜“å°å’Œæ—¥æœŸçš„æ”¶ç›ŠæŒ‡æ¨™
    Args:
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
        symbol: äº¤æ˜“å°ç¬¦è™Ÿ (å¯é¸)
    Returns:
        DataFrame: åŒ…å«æ‰€æœ‰çµæœçš„DataFrame
    """
    try:
        db = DatabaseManager()
        
        print(f"ğŸš€ SQLå„ªåŒ–ç‰ˆæœ¬ï¼šè¨ˆç®—æ”¶ç›ŠæŒ‡æ¨™...")
        print(f"   æ™‚é–“ç¯„åœ: {start_date} åˆ° {end_date}")
        if symbol:
            print(f"   äº¤æ˜“å°: {symbol}")
        
        # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
        where_conditions = ["DATE(timestamp_utc) BETWEEN ? AND ?"]
        params = [start_date, end_date]
        
        if symbol:
            where_conditions.append("symbol = ?")
            params.append(symbol)
        
        where_clause = " AND ".join(where_conditions)
        
        # SQLå„ªåŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨Window Functionsä¸€æ¬¡æ€§è¨ˆç®—æ‰€æœ‰æ”¶ç›ŠæŒ‡æ¨™
        query = f"""
        WITH daily_returns AS (
            -- ç¬¬ä¸€æ­¥ï¼šæŒ‰äº¤æ˜“å°å’Œæ—¥æœŸèšåˆæ¯æ—¥æ”¶ç›Š
            SELECT 
                symbol || '_' || exchange_a || '_' || exchange_b as trading_pair,
                DATE(timestamp_utc) as date,
                SUM(diff_ab) as daily_return
            FROM funding_rate_diff 
            WHERE {where_clause}
            GROUP BY trading_pair, date
            ORDER BY trading_pair, date
        ),
        rolling_calculations AS (
            -- ç¬¬äºŒæ­¥ï¼šä½¿ç”¨Window Functionsè¨ˆç®—æ»‘å‹•çª—å£æ”¶ç›Š
            SELECT 
                trading_pair,
                date,
                daily_return,
                -- 1å¤©æ”¶ç›Š (ç•¶å¤©)
                daily_return as return_1d,
                
                -- 2å¤©æ”¶ç›Š (ç•¶å¤©+å‰1å¤©)
                SUM(daily_return) OVER (
                    PARTITION BY trading_pair 
                    ORDER BY date 
                    ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
                ) as return_2d,
                
                -- 7å¤©æ”¶ç›Š (ç•¶å¤©+å‰6å¤©)
                SUM(daily_return) OVER (
                    PARTITION BY trading_pair 
                    ORDER BY date 
                    ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
                ) as return_7d,
                
                -- 14å¤©æ”¶ç›Š (ç•¶å¤©+å‰13å¤©)
                SUM(daily_return) OVER (
                    PARTITION BY trading_pair 
                    ORDER BY date 
                    ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
                ) as return_14d,
                
                -- 30å¤©æ”¶ç›Š (ç•¶å¤©+å‰29å¤©)
                SUM(daily_return) OVER (
                    PARTITION BY trading_pair 
                    ORDER BY date 
                    ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
                ) as return_30d,
                
                -- å…¨éƒ¨æ”¶ç›Š (å¾é–‹å§‹åˆ°ç•¶å¤©)
                SUM(daily_return) OVER (
                    PARTITION BY trading_pair 
                    ORDER BY date 
                    ROWS UNBOUNDED PRECEDING
                ) as return_all,
                
                -- è¨ˆç®—å¤©æ•¸ç”¨æ–¼ROIè¨ˆç®—
                COUNT(*) OVER (
                    PARTITION BY trading_pair 
                    ORDER BY date 
                    ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
                ) as days_2d,
                
                COUNT(*) OVER (
                    PARTITION BY trading_pair 
                    ORDER BY date 
                    ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
                ) as days_7d,
                
                COUNT(*) OVER (
                    PARTITION BY trading_pair 
                    ORDER BY date 
                    ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
                ) as days_14d,
                
                COUNT(*) OVER (
                    PARTITION BY trading_pair 
                    ORDER BY date 
                    ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
                ) as days_30d,
                
                COUNT(*) OVER (
                    PARTITION BY trading_pair 
                    ORDER BY date 
                    ROWS UNBOUNDED PRECEDING
                ) as days_all
                
            FROM daily_returns
        )
        -- ç¬¬ä¸‰æ­¥ï¼šè¨ˆç®—å¹´åŒ–æ”¶ç›Šç‡ä¸¦è¼¸å‡ºæœ€çµ‚çµæœ
        SELECT 
            trading_pair,
            date,
            COALESCE(return_1d, 0.0) as return_1d,
            COALESCE(return_1d * 365, 0.0) as roi_1d,
            
            COALESCE(return_2d, 0.0) as return_2d,
            COALESCE(CASE WHEN days_2d > 0 THEN return_2d * 365.0 / days_2d ELSE 0.0 END, 0.0) as roi_2d,
            
            COALESCE(return_7d, 0.0) as return_7d,
            COALESCE(CASE WHEN days_7d > 0 THEN return_7d * 365.0 / days_7d ELSE 0.0 END, 0.0) as roi_7d,
            
            COALESCE(return_14d, 0.0) as return_14d,
            COALESCE(CASE WHEN days_14d > 0 THEN return_14d * 365.0 / days_14d ELSE 0.0 END, 0.0) as roi_14d,
            
            COALESCE(return_30d, 0.0) as return_30d,
            COALESCE(CASE WHEN days_30d > 0 THEN return_30d * 365.0 / days_30d ELSE 0.0 END, 0.0) as roi_30d,
            
            COALESCE(return_all, 0.0) as return_all,
            COALESCE(CASE WHEN days_all > 0 THEN return_all * 365.0 / days_all ELSE 0.0 END, 0.0) as roi_all
            
        FROM rolling_calculations
        ORDER BY trading_pair, date
        """
        
        print("ğŸ”„ åŸ·è¡ŒSQLæŸ¥è©¢ä¸­...")
        with db.get_connection() as conn:
            results_df = pd.read_sql_query(query, conn, params=params)
        
        if results_df.empty:
            print("âš ï¸ SQLæŸ¥è©¢æ²’æœ‰è¿”å›ä»»ä½•çµæœ")
            return pd.DataFrame()
        
        print(f"âœ… SQLå„ªåŒ–è¨ˆç®—å®Œæˆ!")
        print(f"   ğŸ“Š è¨ˆç®—çµæœ: {len(results_df)} æ¢è¨˜éŒ„")
        print(f"   ğŸ“… æ—¥æœŸç¯„åœ: {results_df['date'].min()} åˆ° {results_df['date'].max()}")
        print(f"   ğŸ”— äº¤æ˜“å°æ•¸é‡: {results_df['trading_pair'].nunique()}")
        
        return results_df
        
    except Exception as e:
        print(f"âŒ SQLå„ªåŒ–è¨ˆç®—æ™‚å‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()

def process_batch_data_sql_optimized(start_date, end_date, target_dates, symbol=None):
    """
    SQLå„ªåŒ–ç‰ˆæœ¬ï¼šæ‰¹é‡è™•ç†å¤šå€‹æ—¥æœŸçš„æ•¸æ“š
    Args:
        start_date: æ•¸æ“šé–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: æ•¸æ“šçµæŸæ—¥æœŸ (YYYY-MM-DD)
        target_dates: ç›®æ¨™æ—¥æœŸåˆ—è¡¨
        symbol: äº¤æ˜“å°ç¬¦è™Ÿ (å¯é¸)
    Returns:
        DataFrameåŒ…å«æ‰€æœ‰çµæœ
    """
    print(f"ğŸš€ SQLå„ªåŒ–æ‰¹é‡è™•ç†: {len(target_dates)} å€‹æ—¥æœŸ")
    print(f"   æ•¸æ“šç¯„åœ: {start_date} åˆ° {end_date}")
    
    # ä½¿ç”¨SQLä¸€æ¬¡æ€§è¨ˆç®—æ‰€æœ‰çµæœ
    all_results = calculate_returns_sql_optimized(start_date, end_date, symbol)
    
    if all_results.empty:
        print("âš ï¸ æ²’æœ‰è¨ˆç®—å‡ºä»»ä½•çµæœ")
        return pd.DataFrame()
    
    # éæ¿¾å‡ºç›®æ¨™æ—¥æœŸçš„çµæœ
    target_dates_set = set(target_dates)
    filtered_results = all_results[all_results['date'].isin(target_dates_set)].copy()
    
    if filtered_results.empty:
        print("âš ï¸ ç›®æ¨™æ—¥æœŸæ²’æœ‰åŒ¹é…çš„çµæœ")
        return pd.DataFrame()
    
    print(f"âœ… æ‰¹é‡è™•ç†å®Œæˆ!")
    print(f"   ğŸ“Š ç¸½çµæœ: {len(filtered_results)} æ¢è¨˜éŒ„")
    print(f"   ğŸ“… å¯¦éš›æ—¥æœŸ: {filtered_results['date'].nunique()} å¤©")
    print(f"   ğŸ”— äº¤æ˜“å°: {filtered_results['trading_pair'].nunique()} å€‹")
    
    return filtered_results

def process_daily_data_legacy(combined_df, target_date):
    """
    èˆŠç‰ˆæœ¬çš„è™•ç†å‡½æ•¸ (ä¿ç•™å‘å¾Œå…¼å®¹)
    Args:
        combined_df: åˆä½µçš„FRå·®ç•°æ•¸æ“š
        target_date: ç›®æ¨™æ—¥æœŸ (YYYY-MM-DD)
    Returns:
        DataFrameåŒ…å«æ‰€æœ‰äº¤æ˜“å°çš„æ”¶ç›ŠæŒ‡æ¨™
    """
    print(f"âš ï¸ ä½¿ç”¨èˆŠç‰ˆè™•ç†æ–¹å¼è™•ç† {target_date}")
    print("ğŸ’¡ å»ºè­°å‡ç´šåˆ°SQLå„ªåŒ–ç‰ˆæœ¬ä»¥ç²å¾—æ›´å¥½æ€§èƒ½")
    
    # é€™è£¡ä¿ç•™åŸä¾†çš„é‚è¼¯ä½œç‚ºå‚™ç”¨
    # å¯¦éš›ä¸Šæˆ‘å€‘æœƒåœ¨mainå‡½æ•¸ä¸­é¿å…èª¿ç”¨é€™å€‹å‡½æ•¸
    return pd.DataFrame()

def save_returns_to_database(results_df):
    """
    å°‡æ”¶ç›ŠæŒ‡æ¨™ä¿å­˜åˆ°æ•¸æ“šåº«
    Args:
        results_df: åŒ…å«æ”¶ç›ŠæŒ‡æ¨™çš„DataFrame
    Returns:
        ä¿å­˜çš„è¨˜éŒ„æ•¸
    """
    if results_df.empty:
        print("âš ï¸ æ”¶ç›Šæ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•ä¿å­˜")
        return 0
    
    try:
        db = DatabaseManager()
        
        print(f"ğŸ“Š æº–å‚™å°‡ {len(results_df)} æ¢æ”¶ç›ŠæŒ‡æ¨™è¨˜éŒ„æ’å…¥æ•¸æ“šåº«...")
        
        # æº–å‚™æ•¸æ“šåº«æ•¸æ“š
        db_df = results_df.copy()
        
        # è™•ç†åˆ—åæ˜ å°„
        column_mapping = {
            'Trading_Pair': 'trading_pair',
            'Date': 'date',
            '1d_return': 'return_1d',
            '1d_ROI': 'roi_1d',
            '2d_return': 'return_2d', 
            '2d_ROI': 'roi_2d',
            '7d_return': 'return_7d',
            '7d_ROI': 'roi_7d',
            '14d_return': 'return_14d',
            '14d_ROI': 'roi_14d',
            '30d_return': 'return_30d',
            '30d_ROI': 'roi_30d',
            'all_return': 'return_all',
            'all_ROI': 'roi_all'
        }
        
        # é‡å‘½ååˆ—
        for old_col, new_col in column_mapping.items():
            if old_col in db_df.columns:
                db_df[new_col] = db_df[old_col]
        
        # ç¢ºä¿æœ‰æ‰€æœ‰å¿…éœ€çš„åˆ—
        required_columns = ['trading_pair', 'date', 'return_1d', 'roi_1d', 'return_2d', 'roi_2d',
                          'return_7d', 'roi_7d', 'return_14d', 'roi_14d', 'return_30d', 'roi_30d',
                          'return_all', 'roi_all']
        
        for col in required_columns:
            if col not in db_df.columns:
                db_df[col] = 0.0  # é è¨­å€¼
        
        # é¸æ“‡éœ€è¦çš„åˆ—
        db_df = db_df[required_columns].copy()
        
        print(f"ğŸ“Š æ•¸æ“šæ¨£æœ¬: Trading_Pair={db_df.iloc[0]['trading_pair']}, Date={db_df.iloc[0]['date']}")
        
        # ä¿å­˜åˆ°æ•¸æ“šåº«
        inserted_count = db.insert_return_metrics(db_df)
        print(f"âœ… æ•¸æ“šåº«æ’å…¥æˆåŠŸ: {inserted_count} æ¢è¨˜éŒ„")
        
        return inserted_count
        
    except Exception as e:
        print(f"âŒ ä¿å­˜æ”¶ç›Šæ•¸æ“šåˆ°æ•¸æ“šåº«æ™‚å‡ºéŒ¯: {e}")
        return 0

def check_existing_return_data():
    """
    æª¢æŸ¥æ•¸æ“šåº«ä¸­å·²å­˜åœ¨çš„æ”¶ç›Šæ•¸æ“šï¼Œå›å‚³å·²è™•ç†çš„æ—¥æœŸé›†åˆ
    Returns:
        set: å·²è™•ç†çš„æ—¥æœŸé›†åˆ
    """
    print("ğŸ” æª¢æŸ¥æ•¸æ“šåº«ä¸­å·²å­˜åœ¨çš„æ”¶ç›Šæ•¸æ“š...")
    
    try:
        db = DatabaseManager()
        
        # æŸ¥è©¢æ•¸æ“šåº«ä¸­æ‰€æœ‰ä¸é‡è¤‡çš„æ—¥æœŸ
        query = "SELECT DISTINCT date FROM return_metrics ORDER BY date"
        
        with db.get_connection() as conn:
            result = pd.read_sql_query(query, conn)
        
        if result.empty:
            print("ğŸ“Š æ•¸æ“šåº«ä¸­æ²’æœ‰æ”¶ç›Šæ•¸æ“š")
            return set()
        
        existing_dates = set(result['date'].tolist())
        
        print(f"ğŸ“Š æ•¸æ“šåº«ä¸­æ‰¾åˆ° {len(existing_dates)} å€‹å·²è™•ç†çš„æ—¥æœŸ")
        if existing_dates:
            sorted_dates = sorted(existing_dates)
            print(f"ğŸ“… æ•¸æ“šåº«å·²è™•ç†ç¯„åœ: {sorted_dates[0]} åˆ° {sorted_dates[-1]}")
        
        return existing_dates
        
    except Exception as e:
        print(f"âš ï¸ æª¢æŸ¥æ•¸æ“šåº«æ™‚å‡ºéŒ¯: {e}")
        return set()

def auto_detect_date_range():
    """
    è‡ªå‹•æª¢æ¸¬æ•¸æ“šåº«ä¸­funding_rate_diffæ•¸æ“šçš„æ—¥æœŸç¯„åœ
    Returns:
        tuple: (start_date, end_date) æˆ– (None, None)
    """
    print("ğŸ” è‡ªå‹•æƒææ•¸æ“šåº«ä¸­çš„FR_diffæ•¸æ“šç¯„åœ...")
    
    try:
        db = DatabaseManager()
        
        # æŸ¥è©¢æœ€å°å’Œæœ€å¤§æ—¥æœŸ
        query = """
            SELECT MIN(DATE(timestamp_utc)) as min_date, 
                   MAX(DATE(timestamp_utc)) as max_date,
                   COUNT(*) as total_count,
                   COUNT(DISTINCT symbol) as symbol_count
            FROM funding_rate_diff
        """
        
        with db.get_connection() as conn:
            result = conn.execute(query).fetchone()
        
        if not result or result[2] == 0:
            print("âŒ æ•¸æ“šåº«ä¸­æ²’æœ‰æ‰¾åˆ°funding_rate_diffæ•¸æ“š")
            return None, None
        
        min_date = result[0]
        max_date = result[1]
        total_count = result[2]
        symbol_count = result[3]
        
        print(f"ğŸ“ˆ æª¢æ¸¬åˆ°æ•¸æ“šç¯„åœ: {min_date} åˆ° {max_date}")
        print(f"ğŸ“Š ç¸½è¨˜éŒ„æ•¸: {total_count}")
        print(f"ğŸ“… äº¤æ˜“å°æ•¸é‡: {symbol_count}")
        
        return min_date, max_date
        
    except Exception as e:
        print(f"âŒ è‡ªå‹•æª¢æ¸¬æ•¸æ“šç¯„åœæ™‚å‡ºéŒ¯: {e}")
        return None, None

def generate_date_range(start_date, end_date):
    """
    ç”Ÿæˆæ—¥æœŸç¯„åœ
    Args:
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
    Returns:
        list: æ—¥æœŸå­—ç¬¦ä¸²åˆ—è¡¨
    """
    start_dt = datetime.strptime(start_date, '%Y-%m-%d')
    end_dt = datetime.strptime(end_date, '%Y-%m-%d')
    
    dates = []
    current_dt = start_dt
    
    while current_dt <= end_dt:
        dates.append(current_dt.strftime('%Y-%m-%d'))
        current_dt += timedelta(days=1)
    
    return dates

def save_to_database_optimized(db, results_df):
    """
    SQLå„ªåŒ–ç‰ˆæœ¬ï¼šæ‰¹é‡ä¿å­˜æ”¶ç›Šæ•¸æ“šåˆ°æ•¸æ“šåº«
    Args:
        db: DatabaseManagerå¯¦ä¾‹
        results_df: åŒ…å«æ”¶ç›Šæ•¸æ“šçš„DataFrame (SQLæŸ¥è©¢çµæœæ ¼å¼)
    Returns:
        bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
    """
    if results_df.empty:
        print("âš ï¸ æ²’æœ‰æ•¸æ“šéœ€è¦ä¿å­˜")
        return False
    
    try:
        print(f"ğŸ’¾ SQLå„ªåŒ–ä¿å­˜: {len(results_df)} æ¢æ”¶ç›Šè¨˜éŒ„...")
        
        # SQLå„ªåŒ–ç‰ˆæœ¬çš„DataFrameå·²ç¶“æœ‰æ­£ç¢ºçš„åˆ—åæ ¼å¼
        # ç¢ºä¿åˆ—åç¬¦åˆæ•¸æ“šåº«æœŸæœ›
        required_columns = [
            'trading_pair', 'date',
            'return_1d', 'roi_1d',
            'return_2d', 'roi_2d', 
            'return_7d', 'roi_7d',
            'return_14d', 'roi_14d',
            'return_30d', 'roi_30d',
            'return_all', 'roi_all'
        ]
        
        # æª¢æŸ¥æ‰€éœ€åˆ—æ˜¯å¦å­˜åœ¨
        missing_columns = [col for col in required_columns if col not in results_df.columns]
        if missing_columns:
            print(f"âŒ ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
            print(f"   ç¾æœ‰åˆ—: {list(results_df.columns)}")
            return False
        
        # å‰µå»ºç”¨æ–¼æ•¸æ“šåº«æ’å…¥çš„DataFrame
        db_df = results_df[required_columns].copy()
        
        # ç¢ºä¿æ•¸æ“šé¡å‹æ­£ç¢º
        db_df['date'] = pd.to_datetime(db_df['date']).dt.strftime('%Y-%m-%d')
        
        # ç¢ºä¿æ•¸å€¼åˆ—ç‚ºæµ®é»æ•¸
        numeric_columns = [col for col in required_columns if col not in ['trading_pair', 'date']]
        for col in numeric_columns:
            db_df[col] = pd.to_numeric(db_df[col], errors='coerce').fillna(0.0)
        
        print(f"ğŸ“Š æ•¸æ“šç¯„ä¾‹: Trading_Pair={db_df.iloc[0]['trading_pair']}, Date={db_df.iloc[0]['date']}")
        
        # æ‰¹é‡æ’å…¥åˆ°æ•¸æ“šåº«
        inserted_count = db.insert_return_metrics(db_df)
        
        if inserted_count > 0:
            print(f"âœ… SQLå„ªåŒ–ä¿å­˜æˆåŠŸ: {inserted_count} æ¢è¨˜éŒ„")
            return True
        else:
            print("âŒ æ²’æœ‰è¨˜éŒ„è¢«æ’å…¥")
            return False
        
    except Exception as e:
        print(f"âŒ SQLå„ªåŒ–ä¿å­˜æ™‚å‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def find_new_dates_to_process(db, start_date, end_date):
    """
    æ‰¾åˆ°éœ€è¦è™•ç†çš„æ–°æ—¥æœŸ
    Args:
        db: DatabaseManagerå¯¦ä¾‹
        start_date: é–‹å§‹æ—¥æœŸ
        end_date: çµæŸæ—¥æœŸ
    Returns:
        list: éœ€è¦è™•ç†çš„æ—¥æœŸåˆ—è¡¨
    """
    existing_dates = check_existing_return_data()
    all_dates = generate_date_range(start_date, end_date)
    new_dates = [date for date in all_dates if date not in existing_dates]
    return new_dates

def find_latest_unprocessed_date(db):
    """
    æ‰¾åˆ°æœ€æ–°çš„æœªè™•ç†æ—¥æœŸ
    Args:
        db: DatabaseManagerå¯¦ä¾‹
    Returns:
        str: æœ€æ–°æœªè™•ç†æ—¥æœŸæˆ–None
    """
    # æª¢æŸ¥funding_rate_diffè¡¨ä¸­çš„æœ€æ–°æ—¥æœŸ
    try:
        with db.get_connection() as conn:
            query = "SELECT MAX(DATE(timestamp_utc)) as max_date FROM funding_rate_diff"
            result = conn.execute(query).fetchone()
            
            if not result or not result[0]:
                return None
                
            latest_data_date = result[0]
        
        # æª¢æŸ¥return_metricsè¡¨ä¸­çš„æœ€æ–°æ—¥æœŸ
        existing_dates = check_existing_return_data()
        
        if not existing_dates:
            # å¦‚æœæ²’æœ‰ä»»ä½•è™•ç†éçš„æ—¥æœŸï¼Œè¿”å›æœ€æ–°æ•¸æ“šæ—¥æœŸ
            return latest_data_date
        
        latest_processed_date = max(existing_dates)
        
        # å¦‚æœæœ€æ–°æ•¸æ“šæ—¥æœŸæ¯”æœ€æ–°è™•ç†æ—¥æœŸæ–°ï¼Œè¿”å›æœªè™•ç†çš„æ—¥æœŸ
        if latest_data_date > latest_processed_date:
            return latest_data_date
        
        return None
        
    except Exception as e:
        print(f"âŒ æª¢æŸ¥æœªè™•ç†æ—¥æœŸæ™‚å‡ºéŒ¯: {e}")
        return None

def main():
    print("ğŸš€ è³‡é‡‘è²»ç‡æ”¶ç›Šè¨ˆç®—ç¨‹å¼å•Ÿå‹• (SQLå„ªåŒ–ç‰ˆæœ¬ v2)")
    
    parser = argparse.ArgumentParser(description='è¨ˆç®—è³‡é‡‘è²»ç‡æ”¶ç›ŠæŒ‡æ¨™ - SQLå„ªåŒ–ç‰ˆæœ¬')
    parser.add_argument('--start-date', type=str, help='é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--end-date', type=str, help='çµæŸæ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--symbol', type=str, help='äº¤æ˜“å°ç¬¦è™Ÿ (å¯é¸)')
    parser.add_argument('--process-latest', action='store_true', help='è™•ç†æœ€æ–°çš„æœªè™•ç†æ—¥æœŸ')
    parser.add_argument('--use-legacy', action='store_true', help='ä½¿ç”¨èˆŠç‰ˆè™•ç†æ–¹å¼ (ä¸æ¨è–¦)')
    
    args = parser.parse_args()
    
    print("\n" + "="*60)
    print("ğŸ“… è³‡é‡‘è²»ç‡æ”¶ç›Šè¨ˆç®— v2 (SQLå„ªåŒ–ç‰ˆæœ¬)")
    print("="*60)
    
    try:
        # åˆå§‹åŒ–æ•¸æ“šåº«ç®¡ç†å™¨
        db = DatabaseManager()
        print("âœ… æ•¸æ“šåº«åˆå§‹åŒ–å®Œæˆ")
        
        if args.process_latest:
            # æŸ¥æ‰¾æœ€æ–°çš„æœªè™•ç†æ—¥æœŸ
            latest_date = find_latest_unprocessed_date(db)
            if latest_date:
                print(f"ğŸ¯ ç™¼ç¾æœªè™•ç†æ—¥æœŸ: {latest_date}")
                
                # SQLå„ªåŒ–ç‰ˆæœ¬ï¼šè¨ˆç®—æ•¸æ“šç¯„åœ
                start_load_date = (pd.to_datetime(latest_date) - pd.Timedelta(days=30)).strftime('%Y-%m-%d')
                
                # ä½¿ç”¨SQLå„ªåŒ–æ‰¹é‡è™•ç†
                results_df = process_batch_data_sql_optimized(
                    start_load_date, latest_date, [latest_date], args.symbol
                )
                
                if not results_df.empty:
                    # ä¿å­˜åˆ°æ•¸æ“šåº«
                    success = save_to_database_optimized(db, results_df)
                    if success:
                        print(f"âœ… {latest_date} çš„æ”¶ç›ŠæŒ‡æ¨™å·²æˆåŠŸä¿å­˜åˆ°æ•¸æ“šåº«")
                    else:
                        print(f"âŒ ä¿å­˜ {latest_date} çš„æ•¸æ“šåˆ°æ•¸æ“šåº«å¤±æ•—")
                else:
                    print(f"âš ï¸ {latest_date} æ²’æœ‰è¨ˆç®—å‡ºæ”¶ç›ŠæŒ‡æ¨™")
            else:
                print("âœ… æ²’æœ‰ç™¼ç¾æœªè™•ç†çš„æ—¥æœŸï¼Œæ‰€æœ‰æ•¸æ“šéƒ½æ˜¯æœ€æ–°çš„")
            return
        
        # å¦‚æœæŒ‡å®šäº†æ—¥æœŸç¯„åœ
        if args.start_date and args.end_date:
            start_date = args.start_date
            end_date = args.end_date
        else:
            # è‡ªå‹•æª¢æ¸¬æ•¸æ“šç¯„åœ
            start_date, end_date = auto_detect_date_range()
            
            if start_date is None or end_date is None:
                print("âŒ ç„¡æ³•æª¢æ¸¬æ•¸æ“šç¯„åœ")
                print("ğŸ’¡ æç¤º:")
                print("   1. æª¢æŸ¥æ•¸æ“šåº«ä¸­æ˜¯å¦æœ‰funding_rate_diffæ•¸æ“š")
                print("   2. æˆ–ä½¿ç”¨ --start-date å’Œ --end-date åƒæ•¸æŒ‡å®šç¯„åœ")
                return
        
        print(f"ğŸ“… è™•ç†æ—¥æœŸç¯„åœ: {start_date} åˆ° {end_date}")
        
        # æŸ¥æ‰¾é€™å€‹ç¯„åœå…§éœ€è¦è™•ç†çš„æ–°æ—¥æœŸ
        new_dates = find_new_dates_to_process(db, start_date, end_date)
        
        if not new_dates:
            print("âœ… åœ¨æŒ‡å®šæ—¥æœŸç¯„åœå…§æ²’æœ‰ç™¼ç¾éœ€è¦è™•ç†çš„æ–°æ—¥æœŸ")
            return
        
        print(f"ğŸ¯ ç™¼ç¾ {len(new_dates)} å€‹éœ€è¦è™•ç†çš„æ—¥æœŸ")
        if len(new_dates) <= 10:
            print(f"   æ–°æ—¥æœŸ: {', '.join(new_dates)}")
        else:
            print(f"   æ–°æ—¥æœŸç¯„åœ: {new_dates[0]} åˆ° {new_dates[-1]}")
        
        # æ“´å±•é–‹å§‹æ—¥æœŸä»¥åŒ…å«è¶³å¤ çš„æ­·å²æ•¸æ“š
        extended_start_date = (pd.to_datetime(start_date) - pd.Timedelta(days=30)).strftime('%Y-%m-%d')
        
        if args.use_legacy:
            print("âš ï¸ ä½¿ç”¨èˆŠç‰ˆè™•ç†æ–¹å¼ (æ€§èƒ½è¼ƒä½)")
            print("ğŸ’¡ å»ºè­°ç§»é™¤ --use-legacy åƒæ•¸ä»¥ä½¿ç”¨SQLå„ªåŒ–ç‰ˆæœ¬")
            
            # èˆŠç‰ˆè™•ç†æ–¹å¼ (ä¿ç•™å‘å¾Œå…¼å®¹)
            combined_df = load_fr_diff_data_from_database(extended_start_date, end_date, args.symbol)
            
            if combined_df.empty:
                print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•æ•¸æ“š")
                return
            
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(combined_df)} ç­†FRå·®ç•°æ•¸æ“š")
            
            # è™•ç†æ¯å€‹æ–°æ—¥æœŸ
            all_results = []
            for date in new_dates:
                print(f"\nğŸ”„ è™•ç†æ—¥æœŸ: {date}")
                results_df = process_daily_data_legacy(combined_df, date)
                
                if not results_df.empty:
                    all_results.append(results_df)
                    
                    # ä¿å­˜åˆ°æ•¸æ“šåº«
                    success = save_returns_to_database(results_df)
                    if success > 0:
                        print(f"âœ… {date} çš„æ”¶ç›ŠæŒ‡æ¨™å·²ä¿å­˜åˆ°æ•¸æ“šåº« ({success} ç­†è¨˜éŒ„)")
                    else:
                        print(f"âŒ ä¿å­˜ {date} çš„æ•¸æ“šåˆ°æ•¸æ“šåº«å¤±æ•—")
                else:
                    print(f"âš ï¸ {date} æ²’æœ‰è¨ˆç®—å‡ºæ”¶ç›ŠæŒ‡æ¨™")
        else:
            print("ğŸš€ ä½¿ç”¨SQLå„ªåŒ–ç‰ˆæœ¬ (æ¨è–¦)")
            
            # SQLå„ªåŒ–ç‰ˆæœ¬ï¼šä¸€æ¬¡æ€§æ‰¹é‡è™•ç†æ‰€æœ‰æ—¥æœŸ
            results_df = process_batch_data_sql_optimized(
                extended_start_date, end_date, new_dates, args.symbol
            )
            
            if not results_df.empty:
                # ä¿å­˜åˆ°æ•¸æ“šåº«
                success = save_to_database_optimized(db, results_df)
                if success:
                    print(f"âœ… æ‰€æœ‰æ—¥æœŸçš„æ”¶ç›ŠæŒ‡æ¨™å·²ä¿å­˜åˆ°æ•¸æ“šåº« ({len(results_df)} ç­†è¨˜éŒ„)")
                    
                    # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
                    unique_dates = results_df['date'].nunique()
                    unique_pairs = results_df['trading_pair'].nunique()
                    print(f"ğŸ“Š è™•ç†çµ±è¨ˆ: {unique_dates} å¤©, {unique_pairs} å€‹äº¤æ˜“å°")
                else:
                    print(f"âŒ ä¿å­˜æ•¸æ“šåˆ°æ•¸æ“šåº«å¤±æ•—")
            else:
                print("âš ï¸ æ²’æœ‰è¨ˆç®—å‡ºä»»ä½•æ”¶ç›ŠæŒ‡æ¨™")
        
        print(f"\nğŸ‰ è™•ç†å®Œæˆ!")
            
    except Exception as e:
        print(f"âŒ ç¨‹å¼åŸ·è¡Œå‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 